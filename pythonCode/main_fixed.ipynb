{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc17587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymatreader import read_mat\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2c1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursionStart(spectra):\n",
    "    featurePairs = []\n",
    "    maxima = []\n",
    "    minima = []\n",
    "    \n",
    "    for i in range(1, len(spectra) - 1):\n",
    "        if spectra[i] > spectra[i-1]:\n",
    "            if spectra[i] >= spectra[i+1]:\n",
    "                for j in range(i+1, len(spectra)):\n",
    "                    if spectra[i] > spectra[j]:\n",
    "                        maxima.append([i, spectra[i]])\n",
    "                        break\n",
    "                    elif spectra[i] < spectra[j]:\n",
    "                        break\n",
    "        if spectra[i] < spectra[i-1]:\n",
    "            if spectra[i] <= spectra[i+1]:\n",
    "                for j in range(i+1, len(spectra)):\n",
    "                    if spectra[i] < spectra[j]:\n",
    "                        minima.append([i, spectra[i]])\n",
    "                        break\n",
    "                    elif spectra[i] > spectra[j]:\n",
    "                        break\n",
    "    maxima.sort(key = lambda element: element[1], reverse = True)\n",
    "    minima.sort(key = lambda element: element[1])\n",
    "    \n",
    "    globalMaxima = maxima.pop(0)\n",
    "    featurePairs.append([globalMaxima[0], globalMaxima[1] - minima[0][1]])\n",
    "    \n",
    "    recursionStep(0, globalMaxima[0], maxima.copy(), minima.copy(), featurePairs)\n",
    "    recursionStep(len(spectra) - 1, globalMaxima[0], maxima.copy(), minima.copy(), featurePairs)\n",
    "    \n",
    "    return featurePairs\n",
    "\n",
    "def recursionStep(start, end, maxima, minima, featurePairs):\n",
    "    factor = 1\n",
    "    if end < start:\n",
    "        factor = -1\n",
    "    currentMaxima = []\n",
    "    for i in range(len(maxima)):\n",
    "        position = maxima[i][0]\n",
    "        if start * factor < position * factor and position * factor < end * factor:\n",
    "            currentMaxima.append(maxima[i])\n",
    "    if len(currentMaxima) == 0:\n",
    "        return\n",
    "    localMaxima = currentMaxima.pop(0)\n",
    "    recursionStep(start, localMaxima[0], currentMaxima.copy(), minima.copy(), featurePairs)\n",
    "    currentMinima = []\n",
    "    for i in range(len(minima)):\n",
    "        position = minima[i][0]\n",
    "        if localMaxima[0] * factor < position * factor and position * factor < end * factor:\n",
    "            currentMinima.append(minima[i])\n",
    "    localMinima = currentMinima.pop(0)\n",
    "    featurePairs.append([localMaxima[0], localMaxima[1] - localMinima[1]])\n",
    "    recursionStep(localMinima[0], localMaxima[0], currentMaxima.copy(), currentMinima.copy(), featurePairs)\n",
    "    recursionStep(localMinima[0], end, currentMaxima.copy(), currentMinima.copy(), featurePairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d799ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPersistenceTransformation(data_X, listOfK):\n",
    "    spectras = []\n",
    "    for i in range(len(data_X)):\n",
    "        featurePairs = recursionStart(data_X.iloc[i])\n",
    "        featurePairs.sort(key = lambda element: element[1], reverse = True)\n",
    "        spectras.append(featurePairs)\n",
    "        \n",
    "    spectrasForEachK = []\n",
    "    \n",
    "    for k in listOfK:\n",
    "        transformationForSpectra = []\n",
    "        for i in range(0, len(spectras)):\n",
    "            transformation = [0] * len(data_X.iloc[i])\n",
    "            featurePairs = spectras[i][0:round(k*len(spectras[i]))]\n",
    "            for x, fx in featurePairs:\n",
    "                transformation[x] = fx\n",
    "            transformationForSpectra.append(transformation)\n",
    "        spectrasForEachK.append(transformationForSpectra)\n",
    "    return spectrasForEachK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3242a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvAccuracy(tmas, X, resp, classifier, ntrees = 150):\n",
    "    \n",
    "    tmas_names = ['TMA_1:', 'TMA_2:', 'TMA_3:', 'TMA_4:', 'TMA_5:', 'TMA_6:', 'TMA_7:', 'TMA_8:']\n",
    "    \n",
    "    tmas_res_test   = []\n",
    "    tmas_vals_test  = []\n",
    "    tmas_res_train  = []\n",
    "    tmas_vals_train = []\n",
    "    #WE fix this params in order to prevent from overfitting\n",
    "    \n",
    "    mtry =  round(math.sqrt(p))\n",
    "    for tma in range(1, len(tmas_names)+1):\n",
    "    \n",
    "        X_train = X.iloc[tmas[tmas != tma].index, :]\n",
    "\n",
    "        X_test = X.iloc[tmas[tmas == tma].index, :]\n",
    "\n",
    "        y_train = resp.iloc[tmas[tmas != tma].index, :]\n",
    "\n",
    "        y_test = resp.iloc[tmas[tmas == tma].index, :]\n",
    "        \n",
    "        if (classifier == 'logit'):\n",
    "\n",
    "            np.random.seed(1234)\n",
    "            \n",
    "            logreg = LogisticRegression(penalty = None, solver = 'newton-cg',fit_intercept=True, random_state = 1234)\n",
    "\n",
    "            logreg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "            y_pred = logreg.predict_proba(X_test)\n",
    "\n",
    "            y_pred_1 = np.where(y_pred[:, 1] > 0.5, 1, 0)\n",
    "\n",
    "            accuracy = balanced_accuracy_score(y_test, y_pred_1)\n",
    "            \n",
    "            tmas_vals_test.append(accuracy)\n",
    "\n",
    "            tmp_tmas = [tmas_names[tma-1], accuracy]\n",
    "\n",
    "            tmas_res_test.append(tmp_tmas)\n",
    "            \n",
    "        if (classifier == 'rf'):\n",
    "            \n",
    "            rf = RandomForestClassifier(n_estimators= ntrees, random_state= 1234, criterion = 'gini',\n",
    "                                        n_jobs = 8, max_features = 41 )\n",
    "            \n",
    "            rf.fit(X_train, y_train.values.ravel())\n",
    "            \n",
    "            y_pred_rf = rf.predict(X_test)\n",
    "            \n",
    "            accuracy = balanced_accuracy_score(y_test, y_pred_rf)\n",
    "            \n",
    "            tmas_vals_test.append(accuracy)\n",
    "\n",
    "            tmp_tmas = [tmas_names[tma-1], accuracy]\n",
    "\n",
    "            tmas_res_test.append(tmp_tmas)\n",
    "        \n",
    "    return tmas_vals_test, tmas_res_test  \n",
    "\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859854bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data from Matlab\n",
    "dataMaldi = read_mat('data/L1-8_tic_ad_sq.mat')\n",
    "\n",
    "X_values = pd.DataFrame(dataMaldi['data_tic'])#Reading the mz-values \n",
    "                                #to get pd's as input for the ml\n",
    "classes = pd.DataFrame(dataMaldi['classes'])#The cancer Typ, result for ml\n",
    "\n",
    "mz_values = pd.DataFrame(dataMaldi['mzVector'])\n",
    "\n",
    "TMAs   = pd.Series(dataMaldi['tmas'])\n",
    "\n",
    "p = X_values.shape[1]\n",
    "\n",
    "y = pd.DataFrame(np.where(classes == 1, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af428391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for the processing:  248.56335759162903\n"
     ]
    }
   ],
   "source": [
    "# We experiment over a grid of levels of peaks extraction. Namely, 0.01, 0.05, 0.1., 0.2, 0.3, 0.4, 0.5\n",
    "listOfk = [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "st = time.time()\n",
    "ListOfXk = getPersistenceTransformation(data_X = X_values, listOfK = listOfk)\n",
    "et = time.time()\n",
    "print('Time for the processing: ', et-st)\n",
    "X_k0 = ListOfXk[0]\n",
    "X_k1 = ListOfXk[1]\n",
    "X_k2 = ListOfXk[2]\n",
    "X_k3 = ListOfXk[3]\n",
    "X_k4 = ListOfXk[4]\n",
    "X_k5 = ListOfXk[5]\n",
    "X_k6 = ListOfXk[6]\n",
    "X_k7 = ListOfXk[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1635594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.878371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.067213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.774464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.850903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.892345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.925307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.958738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "count  8.000000\n",
       "mean   0.878371\n",
       "std    0.067213\n",
       "min    0.774464\n",
       "25%    0.850903\n",
       "50%    0.892345\n",
       "75%    0.925307\n",
       "max    0.958738"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_k5_1000, rf_k5_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k5), classifier = 'rf', ntrees = 1000)\n",
    "pd.DataFrame(rf_k5_1000).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac696e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st0 = time.time()\n",
    "#rf_k0_1000, rf_k0_2_1000= cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k0), classifier = 'rf', ntrees = 1000)\n",
    "#et0 = time.time()\n",
    "#print('Time for processing ', listOfk[0], ': ', et0 - st0)\n",
    "#st1 = time.time()\n",
    "#rf_k1_1000, rf_k1_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k1), classifier = 'rf', ntrees = 1000)\n",
    "#et1 = time.time()\n",
    "#print('Time for processing ', listOfk[1], ': ', et1 - st1)\n",
    "st2 = time.time()\n",
    "rf_k2_1000, rf_k2_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k2), classifier = 'rf', ntrees = 1000)\n",
    "et2 = time.time()\n",
    "print('Time for processing ', listOfk[2], ': ', et2 - st2)\n",
    "st3 = time.time()\n",
    "rf_k3_1000, rf_k3_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k3), classifier = 'rf', ntrees = 1000)\n",
    "et3 = time.time()\n",
    "print('Time for processing ', listOfk[3], ': ', et3 - st3)\n",
    "st4 = time.time()\n",
    "rf_k4_1000, rf_k4_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k4), classifier = 'rf', ntrees = 1000)\n",
    "et4 = time.time()\n",
    "print('Time for processing ', listOfk[4], ': ', et4 - st4)\n",
    "st5 = time.time()\n",
    "rf_k5_1000, rf_k5_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k5), classifier = 'rf', ntrees = 1000)\n",
    "et5 = time.time()\n",
    "print('Time for processing ', listOfk[5], ': ', et5 - st5)\n",
    "st6 = time.time()\n",
    "rf_k6_1000, rf_k6_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k6), classifier = 'rf', ntrees = 1000)\n",
    "et6 = time.time()\n",
    "print('Time for processing ', listOfk[6], ': ', et6 - st6)\n",
    "st7 = time.time()\n",
    "rf_k7_1000, rf_k7_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k7), classifier = 'rf', ntrees = 1000)\n",
    "et7 = time.time()\n",
    "print('Time for processing ', listOfk[7], ': ', et7 - st7)\n",
    "st8 = time.time()\n",
    "rf_raw_1000, rf_raw_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = X_values, classifier='rf', ntrees = 1000)\n",
    "et8 = time.time()\n",
    "print('Time for processing the raw data: ', et8 - st8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5541467",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5 = time.time()\n",
    "rf_k5_1000, rf_k5_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k5), classifier = 'rf', ntrees = 2000)\n",
    "et5 = time.time()\n",
    "print('Time for processing ', listOfk[5], ': ', et5 - st5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5 = time.time()\n",
    "rf_k5_1000_top, rf_k5_2_1000_top = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k5), \n",
    "                                              classifier = 'rf', ntrees = 1000)\n",
    "et5 = time.time()\n",
    "print('Time for processing ', listOfk[5], ': ', et5 - st5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ae78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5 = time.time()\n",
    "rf_k6_1000_top, rf_k6_2_1000_top = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k6), \n",
    "                                              classifier = 'rf', ntrees = 2000)\n",
    "et5 = time.time()\n",
    "print('Time for processing ', listOfk[5], ': ', et5 - st5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61838324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(X_k5).mask(pd.DataFrame(X_k5)==0).fillna(pd.DataFrame(X_k5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f016fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5 = time.time()\n",
    "df_top, df_2_1000_top = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(df), \n",
    "                                              classifier = 'rf', ntrees = 1000)\n",
    "et5 = time.time()\n",
    "print('Time for processing ', listOfk[5], ': ', et5 - st5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_top).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad85db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_as_tables = pd.concat([pd.DataFrame(res_k0_1).describe(), pd.DataFrame(res_k1_1).describe(),\n",
    "                              pd.DataFrame(res_k2_1).describe(), pd.DataFrame(res_k3_1).describe(),\n",
    "                              pd.DataFrame(res_k4_1).describe(), pd.DataFrame(res_k5_1).describe(),\n",
    "                              pd.DataFrame(res_k6_1).describe(), pd.DataFrame(res_k7_1).describe(),\n",
    "                               pd.DataFrame(q1).describe()],\n",
    "                              axis=1)\n",
    "results_to_latex = round(results_as_tables, 3)\n",
    "\n",
    "results_to_latex = results_to_latex.set_axis(['k = 0.01', 'k = 0.05', ' k = 0.1', 'k = 0.2', \n",
    "                           'k = 0.25', 'k = 0.3', 'k = 0.4', 'k = 0.5', 'raw'], axis=1)\n",
    "\n",
    "#pd.DataFrame(results_to_latex).style.to_latex('results/logit_results.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7446b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_as_tables_rf_1000 = pd.concat([pd.DataFrame(rf_k0_1000).describe(),\n",
    "                              pd.DataFrame(rf_k1_1000).describe(), pd.DataFrame(rf_k2_1000).describe(),\n",
    "                              pd.DataFrame(rf_k3_1000).describe(), pd.DataFrame(rf_k4_1000).describe(),\n",
    "                              pd.DataFrame(rf_k5_1000).describe(), pd.DataFrame(rf_k6_1000).describe(), \n",
    "                              pd.DataFrame(rf_k7_1000).describe(), pd.DataFrame(rf_raw_1000).describe()],\n",
    "                              axis=1)\n",
    "\n",
    "results_rf_to_latex_1000 = round(results_as_tables_rf_1000, 3)\n",
    "\n",
    "results_rf_to_latex_1000 = results_rf_to_latex_1000.set_axis(['k = 0.01', 'k = 0.05', ' k = 0.1', 'k = 0.2', \n",
    "                           'k = 0.25', 'k = 0.3' ,'k = 0.4', 'k = 0.5', 'raw'], axis=1)\n",
    "\n",
    "#pd.DataFrame(results_rf_to_latex_1000).style.to_latex('results/results_rf_to_latex_1000.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_to_latex_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtry = round(math.sqrt(X_values.shape[0]))\n",
    "\n",
    "feature_importance_best_model = RandomForestClassifier(n_estimators= 1000, random_state= 1234, criterion = 'gini',\n",
    "                                        max_features=mtry)\n",
    "\n",
    "st = time.time()\n",
    "feature_importance_best_model.fit(pd.DataFrame(X_k5), y.values.ravel())\n",
    "et = time.time()\n",
    "print('Time for processing the raw data: ', et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb88341",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtry = round(math.sqrt(X_values.shape[0]))\n",
    "\n",
    "feature_importance_best_model_k_40 = RandomForestClassifier(n_estimators= 1000, random_state= 1234, criterion = 'gini',\n",
    "                                        max_features=mtry)\n",
    "\n",
    "st = time.time()\n",
    "feature_importance_best_model_k_40.fit(pd.DataFrame(X_k6), y.values.ravel())\n",
    "et = time.time()\n",
    "print('Time for processing the raw data: ', et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtry = round(math.sqrt(X_values.shape[0]))\n",
    "\n",
    "feature_importance_raw = RandomForestClassifier(n_estimators= 1000, random_state= 1234, criterion = 'gini',\n",
    "                                        max_features=mtry)\n",
    "\n",
    "st = time.time()\n",
    "feature_importance_raw.fit(pd.DataFrame(X_values), y.values.ravel())\n",
    "et = time.time()\n",
    "\n",
    "print('Time for processing the raw data: ', et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = feature_importance_best_model.feature_importances_\n",
    "forest_importances = pd.Series(importances)\n",
    "std = np.std([tree.feature_importances_ for tree in feature_importance_best_model.estimators_], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax= ax)\n",
    "plt.xticks(np.arange(len(mz_values))[::300].round(), labels= (mz_values.to_numpy()[:,0][::300].round().astype(int)))\n",
    "\n",
    "ax.set_title(\"Feature importances k = 30%\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f732c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mod_impt = pd.DataFrame(dataMaldi['mzVector'])\n",
    "\n",
    "best_mod_impt['imp'] = importances\n",
    "\n",
    "pd.DataFrame(best_mod_impt)\n",
    "\n",
    "best_mod_impt = best_mod_impt.sort_values(by='imp', ascending=False)\n",
    "\n",
    "best_mod_impt[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca68ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_raw = feature_importance_raw.feature_importances_\n",
    "\n",
    "forest_importances_raw = pd.Series(importances_raw)\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in feature_importance_raw.estimators_], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances_raw.plot.bar(yerr=std, ax= ax)\n",
    "plt.xticks(np.arange(len(mz_values))[::300].round(), labels= (mz_values.to_numpy()[:,0][::300].round().astype(int)))\n",
    "\n",
    "ax.set_title(\"Feature importances Raw Data\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_k5).iloc[TMAs[TMAs != 6].index, :]\n",
    "\n",
    "X_test = pd.DataFrame(X_k5).iloc[TMAs[TMAs == 6].index, :]\n",
    "\n",
    "y_train = y.iloc[TMAs[TMAs != 6].index, :]\n",
    "\n",
    "y_test = y.iloc[TMAs[TMAs == 6].index, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518df4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fine tune RF for the best model\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = 2000\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 6]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'criterion':      criterion\n",
    "               }\n",
    "\n",
    "\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=1234)\n",
    "        \n",
    "rf_random = RandomizedSearchCV(estimator = rfc, \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100, cv = 5, verbose=2, \n",
    "                               random_state=1234, n_jobs = -1, scoring = \"balanced_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a03f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c053f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "st8 = time.time()\n",
    "rf_raw_1000, rf_raw_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = X_values, classifier='rf', ntrees = 2000)\n",
    "et8 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "Average(rf_raw_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824faed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "st8 = time.time()\n",
    "rf_k5_2000, rf_k5_2_1000 = cvAccuracy(tmas =TMAs, resp=y, X = pd.DataFrame(X_k5), classifier='rf', ntrees = 2000)\n",
    "et8 = time.time()\n",
    "\n",
    "print('Time for processing the raw data: ', et8 - st8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6113c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvAccuracyTun(tmas, X, resp, trees):\n",
    "    \n",
    "    tmas_names = ['TMA_1:', 'TMA_2:', 'TMA_3:', 'TMA_4:', 'TMA_5:', 'TMA_6:', 'TMA_7:', 'TMA_8:']\n",
    "    \n",
    "    tmas_res_test   = []\n",
    "    tmas_vals_test  = []\n",
    "    tmas_res_train  = []\n",
    "    tmas_vals_train = []\n",
    "    #WE fix this params in order to prevent from overfitting\n",
    "    \n",
    "    mtry =  round(math.sqrt(p))\n",
    "    \n",
    "    for tma in range(1, len(tmas_names)+1):\n",
    "    \n",
    "        X_train = X.iloc[tmas[tmas != tma].index, :]\n",
    "\n",
    "        X_test = X.iloc[tmas[tmas == tma].index, :]\n",
    "\n",
    "        y_train = resp.iloc[tmas[tmas != tma].index, :]\n",
    "\n",
    "        y_test = resp.iloc[tmas[tmas == tma].index, :]\n",
    "        \n",
    "        max_features = ['log2', 'sqrt', round(p/10), round(p/12), round(p/15)] # Maximum number of levels in tree\n",
    "\n",
    "        max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "        \n",
    "        max_depth.append(None) # Minimum number of samples required to split a node\n",
    "\n",
    "        min_samples_split = [2, 5, 10, 15, 20] # Minimum number of samples required at each leaf node\n",
    "\n",
    "        min_samples_leaf = [1, 2, 4, 6] # Method of selecting samples for training each tree\n",
    "\n",
    "        random_grid = {\n",
    "                   'max_depth': max_depth,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth\n",
    "        }\n",
    "\n",
    "        rfc = RandomForestClassifier(random_state=1234)\n",
    "        \n",
    "        rf_random = RandomizedSearchCV(estimator = rfc, \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 50, \n",
    "                               cv = 5, verbose = 3, \n",
    "                               random_state=1234, \n",
    "                               n_jobs = -3, \n",
    "                               scoring = \"f1\")\n",
    "            \n",
    "        rf_random.fit(X_train, y_train.values.ravel())\n",
    "            \n",
    "        print(rf_random.best_params_)\n",
    "        \n",
    "        y_pred_rf = rf_random.predict(X_test)\n",
    "            \n",
    "        accuracy = balanced_accuracy_score(y_test, y_pred_rf)\n",
    "            \n",
    "        tmas_vals_test.append(accuracy)\n",
    "\n",
    "        tmp_tmas = [tmas_names[tma-1], accuracy]\n",
    "\n",
    "        tmas_res_test.append(tmp_tmas)\n",
    "        \n",
    "    return tmas_vals_test, tmas_res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_data = cvAccuracyTun(tmas =TMAs, resp=y, X = pd.DataFrame(X_k5), trees = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tune_data[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885644fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Average(tune_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
